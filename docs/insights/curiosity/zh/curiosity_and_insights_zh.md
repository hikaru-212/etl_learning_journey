# 🧭 好奇心與工程洞察  
> [切換至英文版 / Switch to English Version](../en/curiosity_and_insights_en.md)
---

我的工作與學習，不只是寫程式或做數學推導。我更像一個好奇心的偵探，不斷在不同領域間尋找共通的模式。這份紀錄就是我如何將一個簡單的「為什麼」，轉化為工程與數學上的洞察。

它包含兩個層次的思考：  
1. **好奇心紀錄** → 純探索，跨學科的比喻與實驗設計。  
2. **工程洞察** → 在好奇心的基礎上，嘗試轉化為更嚴謹的工程/數學語言。  


---

## Part I. 好奇心紀錄  

### 主題：零一律與原子寫入 (2025-09-17)
這份紀錄旨在探索一種思考方法，而非提供一個無懈可擊的最終答案。它並非核心專案功能，而是一次出於好奇心的探索。 

**「零一律是否能對應到工程裡的原子寫入？  
AI 本身會同意這樣的比喻嗎？」**  

#### 背景  
在研究與工程中，我常嘗試將數學直覺對應到技術概念。  
這次，我想測試「零一律」——事件要嘛發生，要嘛不發生——是否能類比成 **原子寫入的全有或全無特性**。  

#### 我的好奇  
1. 如果「事件必然發生或不發生」可視為零一律，那麼原子寫入是否就是工程上的對應？  
2. 不同的 AI 對這樣的比喻會如何反應？  
   - 會同意這種跨領域的對比嗎？  
   - 還是會提出反駁？  

#### 詢問 AI 後的結果  
- **AI #1 與 AI #2** → 同意這個比喻。  
- **AI #3** → 不同意，並誤解零一律，把它誤認為是收斂過程。  
- 後來我用數學定義糾正後，AI #3 才承認錯誤。  
- 我的疑問是：連 AI 都會出錯，我如何系統性地驗證其可靠性？這個問題，將我的好奇心從『跨領域比喻』引導至『可重複、可量化的 AI 實驗設計』。 

---

## 理論實驗與工程考量  
以下是我設計的三個實驗，用來測試 AI 行為的邊界：
> **實驗一：重複測試（穩定性）** 
> - **方法：** 對同一個精確問題（例如：零一律 vs 原子寫入）提問 100 或 1000 次。 
> - **指標:** 測量 AI 給出正確答案的機率。
> - **Goal:** 量化 AI在已知問題上的可靠度與穩定性。

> **實驗二: 開放性問題測試（信念分布）**
> - **方法：** 提問一個未解決問題（如黎曼猜想）數百次。
> - **指標:** 分析答案的分布（同意 / 不同意 / 承認「未知」）。
> - **Goal:** 了解AI如何處理沒有明確真值的模糊問題。

> **實驗三：AI 辯論測試（收斂與自我修正）**
> - **方法：** 讓兩個 AI 針對未解決問題進行辯論，並將彼此的推理不斷餵回。
> - **指標:** 觀察它們的立場是否隨迭代改變。
> - **Goal:** 系統是否能透過對話收斂於共識，或進行自我修正。 

   既然人類目前也沒有定論，那麼讓 AI 在「不可判定」的議題上辯論，會產生什麼新現象？  
   
   *備註：* 我設想了這些實驗，但因實際執行的成本考量而未能實施。

---

## 實驗設計與工程考量：計費與實作方式（AI 1號提供）

> **註記：** 為了保持客觀，本紀錄中的 AI 系統一律以代號呈現（如 AI 1、AI 2），重點放在其行為特性，而非特定品牌。  

在進行重複提問（例如 100 或 1000 次）時，**成本**是重要考量。計費並非「每題固定費用」，而是依 **token 用量** 計算：  

1. **計費模型**  
   - 每次請求都會消耗 tokens：  
     - **輸入 tokens**（包含 prompt 與 system 訊息）  
     - **輸出 tokens**（模型回覆）  
   - 成本計算：**（輸入 tokens × 單價）＋（輸出 tokens × 單價）**。  
   - 重複提出**同一個問題**依然會產生**新的請求**，因此會再次消耗 tokens。  
   - 因此，執行 1000 次查詢 ≈ **1000 ×（平均 token 用量）**的總成本。  

   > ⚠️ 重點：不是「按題收費」，而是 **按 token 計費**。  
   > 即使是完全相同的 prompt，每一次請求都會另外計費，因為都會重新消耗 tokens。  

2. **實作（AI 1 號的模板構想）**  
   - 以迴圈重複送出相同 prompt。  
   - 收集回應並分析答案的分布情況。  
   - 為控制成本，限制輸出長度並保持 prompt 精簡。  

### 範例（Python）
> **註解：** 這裡使用 `AI1` 類別作為抽象代號，其行為模擬通用的大型語言模型 API。這麼做是為了將討論重點放在模型行為本身，而非特定品牌或服務。

```python
from AI1 import AI1
import collections

client = AI1()

prompt = "Explain the Zero-One Law in probability theory."
results = []

# 執行相同的 prompt 100 次
for i in range(100):
    response = client.chat.completions.create(
        model="(placeholder)",   # 範例用：不指定實際模型
        messages=[{"role": "user", "content": prompt}],
        max_tokens=150,          # 限制輸出長度以控制成本
        temperature=0            # 降低隨機性，提升一致性
    )
    answer = response.choices[0].message.content.strip()
    results.append(answer)

# 簡單分析：統計唯一答案及其出現次數
counter = collections.Counter(results)
for ans, count in counter.items():
    print(f"{count} 次: {ans[:80]}...")
```

---

### 多 AI 回饋循環  
- 在取得 **AI 1 號** 的初版模板後，我將其交給 **AI 2 號** 審閱。  
- **AI 2 號** 提出若干修正建議（例如：成本描述措辭、參數說明更清楚）。  
- 我再把 **AI 2 號** 的意見回饋給 **AI 1 號**，請它進一步自省與調整。  

### 結論  
- **AI 1 號** 接受了部分建議，並澄清了原本的意圖與假設。  
- 這來回的過程顯示：不同 AI 系統之間可以進行**交叉驗證**與**相互精煉**。  
- 對我而言，重點已不再是追求「完美程式碼」，而是觀察 **AI 推理如何分歧、如何收斂、以及在被挑戰時如何自我修正**。  
- 這些實驗的目的，不僅是驗證 AI 的準確性，更是為了探究其行為模式的邊界，並將這些不可預測的行為，轉化為可分析的數據。

👉 它不只是 AI 的輸出，而是我如何 **學習、驗證與反思** 的過程。  

---

## Part II. 工程洞察：

### 我的好奇心紀錄：AI 錯誤背後的數學比喻  
這份紀錄是我的個人思考過程，嘗試用有限的知識去比喻複雜的技術。我希望透過這個過程，不僅能釐清自己的疑惑，也能展示一種從直觀到嚴謹的學習路徑。

**目標**：探索 AI 行為背後的機制，而不是把它當黑箱工具。  

---

### 源自於AI回答錯誤的思考過程
第一次，我直覺地認為 AI 的運作可能像一個獨立的轉移矩陣。但這個想法很快就被推翻了，因為 AI 顯然能記住我們的對話。

於是我修正了猜想，認為它更像一個帶有記憶性的轉移算子。接著，我將它在單一回合內答錯的結果，類比成「該回合的轉移過程走錯了，陷入了吸收態」。

但這又引發了新的思考：為什麼 AI 在下一回合中，有機會根據我的解釋來修正錯誤？我意識到，這不是因為它「跳出了」吸收態，而是因為在新回合中，它會基於新的上下文，建立一個全新的、帶有修正過記憶的轉移矩陣。

這個過程讓我明白，回合與回合之間的機制，才是理解 AI 行為的關鍵。

### 我的直觀理解 (簡化版)  
- AI 的回答像隨機選擇。  
- 它會記住上下文，就像帶記憶的轉移矩陣。  
- 單回合答錯的結果，感覺像陷入了吸收態。

---

### 更嚴謹的技術理解  

| 面向 | 直觀比喻 (簡化) | 更精確的技術理解 |
|------|-------------------|-----------------|
| **表達方式** | AI 每次回答都像一個新的轉移矩陣，但會繼承之前的記憶。 | 是一個不斷擴展、條件化的大型隨機過程，主要由基於Transformer架構的自回歸模型驅動。 模型會將所有歷史對話作為輸入，透過**注意力機制（Attention Mechanism）**動態地調整其內部狀態。 |
| **吸收態** | 在單一回合內，一旦答錯就像進入吸收態 | 是一種高機率的「局部陷阱」。這不是數學上的「吸收態」，而是在當前上下文條件下，錯誤答案的機率峰值高於正確答案。透過新的輸入（例如你的修正），機率分佈會被重塑，讓正確答案的機率升高。 |
| **回合之間** | 每次對話都像一個新的轉移矩陣，但會繼承之前的記憶 | 每一回合都是一次新的條件運算。模型會將你提供的所有資訊作為輸入，動態地調整內部參數，從而產生基於新資訊的結果。 |
 

---

### 結論  
- 這份紀錄的價值在於，它展示了從直觀比喻到工程洞察的過程。 
- 雖然我的初始猜想使用了不完全精確的轉移矩陣和吸收態等術語，但它們成功捕捉到了 AI 行為的核心特徵：機率性與上下文依賴性。
- 這個過程也揭示了一個重要的學習方法：即使猜測不完全正確，只要能引發更深的探討與修正，就有其意義。這是一個在不熟悉領域中，將抽象概念具象化的有效方式。  
- 同時我也學到，理解一個新事物不需一步到位。從一個不完美的直覺出發，透過批判性反思與學習，最終能建構出更精確、更嚴謹的知識體系。

---

## 📌 總體反思  
這份紀錄展示了我如何從「好奇心」一路走到「工程洞察」：  
1. 做跨領域比喻（數學 ↔ 工程）  
2. 驗證 AI 的正確性與行為模式  
3. 把直觀轉化為技術語言  
4. 最後沉澱為個人的學習方法與工程洞察  


### 📌 洞察：理論與現實的鴻溝
雖然我設計了嚴謹的實驗來驗證 AI 的行為，但實際的「成本」成了最大的障礙。這讓我意識到，在現實世界中，純粹的學術好奇心必須與務實的工程考量（如預算與資源）相權衡。這也強化了我對『核心與促成者』的信念：在資源有限的情況下，優先將資源投入到能解決核心問題的部分。這份紀錄體現了工程師的重要思維：從直觀的現象出發，運用既有知識建立假設，然後透過不斷的質疑與驗證，最終達成更為嚴謹、務實的理解。




